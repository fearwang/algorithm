# 入门篇
## 如何抓住重点
1.学会复杂度分析。

2.学习每种数据结构算法的来历，自身特点，适合解决的问题，实际运用的场景。

3.坚持练习，自己实现课程内容和思考题，然后适度刷题(速度：每周三课)。

4.知识需要沉淀，不行就多刷几遍。

## 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
1.时间空间复杂度，大O表示法。

2.大O表示法：描述的是一段代码随着问题数据规模增长，它的执行时间/占用内存增长的趋势，常见的有线性O(n),常量O(1),对数O(logn)，指数O(2^n),线性对数O(nlogn)，阶乘O(n!)。

3.大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

4.空间复杂度类似。

![复杂度曲线](./resource/picture/复杂度曲线.jpg)

## 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度

1.最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。

2.最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。

3.平均时间复杂度要考虑每种情况出现的概率，算加权平均值。

4.均摊时间复杂度，针对特殊的有规律的情况，无需引入概率方法算加权平均，重点是摊还分析方法。

5.对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

# 基础篇

## 数组：为什么很多编程语言中数组都从0开始编号？
1、数组是线性表的一种，还有栈，队列，链表。

2、非线性表有：树，图

3.数组支持随机访问，且复杂度O(1)

4.插入和删除操作会导致数据移动(为了保证数据连续)，但在特定场景中可以一定程度避免这种移动。比如插入时：如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

![删除数组元素](./resource/picture/arrayInsert.jpg)

5.再看删除操作：在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？ JVM的mark sweep 垃圾回收算法中也有类似思想，先标记，再一次性移除。

6.高级语言比如java中的容器和数组如何选择：绝大多数情况应该选择容器，如果数据大小固定且已知，且操作简单，则也可以用数组。

7.最后为啥数组index从0开始，index定义的是offset即偏移，而数组名一般指定的数组所占空间的起始地址。当然历史原因也可能的。毕竟从汇编角度看地一个元素的offset就是0。

## 链表（上）：如何实现LRU缓存淘汰算法?
加粗部分代码实现一下。

1.**约瑟夫问题**：N个人围成一圈，从约定编号为K的人开始报数，第M个将被杀掉，依次类推，最后剩下一个，其余人都将被杀掉。

2.双链表相对单链表优势，知道要删除的节点时可以直接删除，无需遍历找到prev node。某个指定节点前插入操作类似。

3.链表对cache的预读机制不友好。

4.**如何基于单链表实现lru缓存策略**：对于已经缓存的数据，需要先从当位置删除，然后将数据插入到头部，如果缓存已满还要删除尾部的数据。寻找已经存在的数据需要O(n)，这受制于单链表的特性，可以用hashcode降低为O(1)。

5.**如何基于数组实现lru策略**:和单链表类似，只不过删除插入操作会比较耗时，类似android ams中的process lru，为了避免频繁移动，可以先做特殊标记，插入时如果满了，则一次性移动。

6.**判断单链表回文**：寻找中间节点，反转其中一个，然后二者对比。

## 链表（下）：如何轻松写出正确的链表代码？

1.单链表代码：可以利用哨兵节点简化特殊情况的处理。

2.注意边界处理：链表为空，链表包含一个节点，链表包含2个节点，链表在处理头节点和尾节点时是否OK。

3.**习题**：单链表反转、链表中环的检测（快慢指针）、两个有序的链表合并、删除链表倒数第n个结点（快慢指针）、求链表的中间结点（快慢指针），约瑟夫问题